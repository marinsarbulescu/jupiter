Hi, this is a brief lecture about
the outputs of a data science experiment. So some of the most common forms of
output from a data science experiment include reports, presentations,
interactive web pages and apps. For me probably the most common
output from a data science experiment is a report, and so, let's for
each of these things, talk about the hallmarks of good
output from a data science experiment. So let's focus on reports first. Ideally reports should be clearly written, they should involve
a narrative around the data. A narrative that goes from the data
creation to the analysis to clear conclusions, or if there aren't clear
conclusions, a discussion of why not. So the conclusions should be concise,
and any un-details, or side bars should be left to a minimum,
so omit unnecessary details. I think this is probably one of
the biggest issues with a lot of the reports that I see. But one thing again, in your domain,
how and what is done for reports, there's going to be a lot of,
kind of terms of art and specifics of the art for your case. One thing that we'd like to harp on is
something that's common across most settings, is the idea that
the reports should be reproducible. The idea of reproducibility, is that
if someone goes back to the report, the report and the analysis,
the code that creates the analysis and the data can be embedded
in one single document. And this document will help so that if
someone tries to reproduce the report two months later, say with the same
starting data set, they should get the same numbers, and these tools
will help ensure that can happen. And some of the tools like Ipiecon
notebooks in Nitter and R, are available so that you can help
the people that you manage try to produce reproducible reports. In addition, there's a lot of
benefits to reproducible reports, such as the documents tend to document the
code very well because the documentation, the report itself and the analysis
are embedded in the same document. It helps people think about the analysis, because they're thinking about the report
while they're doing the analysis. So, there's quite a few benefits
to using some of these tools for reproducible research. The same set of criteria should
also go for presentations as well. Presentations should be clear, they should
involve a narrative around the data, they should have concise conclusions, and
they should omit unnecessary details, and maybe less well known is that there's
a lot of tools for reproducibility, for presentations just like there are for
reports. I'm thinking in specifics of
Slidefy in our studio's presenter, and some of these tools that make
very beautiful, nice presentations that similarly embed the analysis and
the presentations into a single document. And in addition to reproducibility,
just like with reports, these have many side benefits of helping
how you think about the presentation, and archival purposes, many other benefits
to this style of creating presentations. It hasn't caught on that much,
not anywhere near as much as the report writing has, but
still it has many benefits. So, I'm gonna lump web pages and apps
together as a single thing to talk about, cuz I think you could make a fairly easy case that an interactive web
page is just an app of a form. And these should be easy to use, they
should have help pages or documentation, and some things that we're gonna talk
a lot about in the specialization of it. The code should be documented well,
so that when you manage someone and they leave and someone else comes
later on to maintain the app or the web page, they'll know how to do it. They'll come in later, or even if
the person who's doing it puts it down for several months and has to go back to it, having good documentation is going
to help them do that better. The second thing that we harp on a lot in
this specialization is that code should be version controlled, and
the tools like Git and GitHub, and other tools like Subversion are available
now, to make version control very easy. So, we think part of best practices
should be executing a culture of version control and reproducibility
in your management process. Let me just go through an app here,
my former master student John Buscheli, who's now a PHd student in the department
working with chip ground created in China. He created this great app for the ENAR, the Eastern North American Regional bio
statistics, bio metrics conference. Where they didn't have a, they didn't
have a website or an interactive website, so he scraped the PDF with a program and
created this website, but it's very easy to use, the fields are all somewhat
obvious, and there's a very clean design. Again, he's not gonna win any awards for
this, but it was highly useful for the collection of people at ENAR, and I think they try to contact
him every year to do it again. Here's another great app that occurred
in the data products class, and I want to kinda harp on one
specific part of this app. This was created by Alex Lem, and this is an app that maps
the Syrian refugee crisis. You click on a component of the map, and then it gives you some demographic
information about the refugees, and this was well and beyond I think what was
required for the data products class. So, he really did a nice job with this and you can see it's a very
beautiful web page. But more than anything, he created some,
he was very considerate to the users by creating some very nice instructions
and a manual over here to the side. It's easy to use, but more importantly, it's very well
documented exactly how to use the app. So I hope in this lecture you got
a little bit of a sense of the kinds of things that could be output from
a data science experiment, the sort of, we like to call them data products that
could result, and maybe some insights, at least some of the insights that we have,
about what make for good data products. Thanks again and
we'll see you in the rest of the class.