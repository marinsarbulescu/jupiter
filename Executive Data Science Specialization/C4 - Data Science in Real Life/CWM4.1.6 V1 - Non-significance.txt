Hi, my name is Brian Caffo and
this is a lecture on non-significance. What I'm going for in this lecture
is to consider the instances where, I shouldn't even call it non-significance,
just where the results of the test or a confidence interval or whatever
are a little bit on the equivocal side. It's kind of easy if you're test are
highly non-significant, it's clear there's no effect, or they're highly significant,
it's clear that there is effect. But what do you do if things
are right on the margin? Maybe just under or just over? So what sorts of things
are you thinking about? So now I have this cartoon here
where you get a P value of 0.051. So what are you most concerned
with with a marginal effect? Well you could be, there's lots
of things that could be going on. One is right. You could just be unlucky. There really is no effect and
there's just some noise in the system and you just happen to get a p value or
hypothesis test that was close to significant or just under significant
but there really is no effect. And that is an unfortunate case,
you're unlucky but another thing that we're often
concerned about is this idea of power. Namely, was the study set up in the first
place to really adjudicate whether or not there was an effect. So, in the presence of equivocal results, the first question you
wanna ask yourself was, was the study set up for
failure by not being adequately powered? So what is power? Power is the probability of detecting
an effect that is truly there. You want more power. Okay, so as an example,
when you're designing a study, studies that have a larger sample
size are gonna have more power. Studies that are trying to detect a bigger
effect are gonna have more power. It's easier to see an elephant
than it is to see a mouse, right? So if there's a bigger
effect it's easier to find. So you're gonna have more power
if the true effect is larger. And the less noise that's in the system, the smaller the variance,
the more power you have. The less uncertainty in the system
that you study, the more power you're gonna have and so often people will do
power calculations prior to a study just in order to make sure that
they've set themselves up for success, that they know
that they have a specific high probability of detecting effect
in effect if it's actually there. I think what you're often
concerned with after a study is if the power was not adequate or at least having the discussion of whether
this study was really set up for success. Unfortunately, post talk, there's not
that much that can be done about power. The obvious thing,
which most of the time's not feasible, is collecting more data, or
doing another study, okay? That will obviously work, okay? But that's often out of your control. But an idea that everyone flirts
with is checking the power post hoc. Using the effects that you saw and doing
some sort of power calculation post hoc. This is generally a bad idea, I think this,
if you're doing this you need to be very sophisticated in the field of statistics
to understand the pitfalls and so on. Usually what are called post hoc power
calculations are a terrible idea so in general the idea of trying to,
via the data, figure out what the power of your study was after you've already
conducted it is almost always a bad idea. So what are you left with if
you can't collect more data or do another study, we've already said that
doing some sort of post hoc calculations to quantify power is usually a bad idea or
at least if you're going to do that and you don't know a lot about it, you should
at least contact a PhD statistician who will probably try and talk you out of
it anyway, all that you're left with is a critical discussion of the strength of
the study and that's your main recourse. Is basically trying to figure out well, it should we have seen
an effect in this study. Is the sample size similar to what we see in other studies
where we do see an effect? This kind of critical review is
what you have at this point for understanding this equivocal result. Okay, so my main point here is that in the presence
of these kinds of marginal results. One of the main points of discussion you
want to have is a discussion over whether or not your study was set up for
success by being adequately powered.